#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analyse Pr√©dictive des Performances Scolaires
===========================================

Ce script impl√©mente une m√©thodologie compl√®te d'analyse des donn√©es √©ducatives
pour pr√©dire et comprendre les facteurs de r√©ussite scolaire.

Auteur: Data Scientist Education
Date: 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Configuration des graphiques
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class AnalyseurPerformanceScolaire:
    """
    Classe principale pour l'analyse pr√©dictive des performances scolaires
    """
    
    def __init__(self, fichier_donnees=None):
        """
        Initialise l'analyseur
        
        Args:
            fichier_donnees (str): Chemin vers le fichier Excel des donn√©es
        """
        self.donnees = None
        self.donnees_nettoyees = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.modeles = {}
        self.meilleur_modele = None
        self.preprocesseur = None
        
        if fichier_donnees:
            self.charger_donnees(fichier_donnees)
    
    def charger_donnees(self, fichier_donnees):
        """
        Charge les donn√©es depuis un fichier Excel
        
        Args:
            fichier_donnees (str): Chemin vers le fichier
        """
        try:
            self.donnees = pd.read_excel(fichier_donnees)
            print(f"‚úì Donn√©es charg√©es avec succ√®s: {self.donnees.shape}")
            return True
        except Exception as e:
            print(f"‚úó Erreur lors du chargement: {e}")
            return False
    
    def generer_donnees_synthetiques(self, n_eleves=300):
        """
        G√©n√®re un jeu de donn√©es synth√©tiques r√©aliste pour les tests
        
        Args:
            n_eleves (int): Nombre d'√©l√®ves √† g√©n√©rer
        """
        np.random.seed(42)
        
        # Variables individuelles
        donnees_synth = {
            # Donn√©es d√©mographiques
            'age': np.random.normal(15, 1.5, n_eleves).clip(12, 18),
            'genre': np.random.choice(['M', 'F'], n_eleves),
            
            # Performance acad√©mique (variable cible)
            'note_francais': np.random.normal(13, 3, n_eleves).clip(0, 20),
            'note_maths': np.random.normal(12, 3.5, n_eleves).clip(0, 20),
            'note_lecture': np.random.normal(13.5, 2.8, n_eleves).clip(0, 20),
            
            # Facteurs comportementaux
            'absences': np.random.poisson(8, n_eleves).clip(0, 50),
            'retards': np.random.poisson(3, n_eleves).clip(0, 20),
            'heures_devoirs': np.random.gamma(2, 1.5, n_eleves).clip(0.5, 8),
            'heures_sommeil': np.random.normal(7.5, 1, n_eleves).clip(5, 10),
            'temps_ecrans': np.random.gamma(2, 2, n_eleves).clip(0, 12),
            
            # Facteurs psychologiques (√©chelle 1-10)
            'motivation': np.random.beta(3, 2, n_eleves) * 9 + 1,
            'confiance_soi': np.random.beta(2.5, 2.5, n_eleves) * 9 + 1,
            'stress': np.random.beta(2, 3, n_eleves) * 9 + 1,
            'perseverance': np.random.beta(3, 2, n_eleves) * 9 + 1,
            
            # Facteurs familiaux
            'niveau_etudes_parents': np.random.choice(['Primaire', 'Secondaire', 'Sup√©rieur'], 
                                                    n_eleves, p=[0.2, 0.5, 0.3]),
            'revenus_famille': np.random.choice(['Faible', 'Moyen', '√âlev√©'], 
                                              n_eleves, p=[0.3, 0.5, 0.2]),
            'suivi_parental': np.random.choice(['Faible', 'Mod√©r√©', 'Fort'], 
                                             n_eleves, p=[0.25, 0.5, 0.25]),
            'nombre_fratrie': np.random.poisson(1.5, n_eleves).clip(0, 6),
            
            # Facteurs scolaires
            'taille_classe': np.random.normal(25, 4, n_eleves).clip(15, 35),
            'type_etablissement': np.random.choice(['Public', 'Priv√©'], n_eleves, p=[0.8, 0.2]),
            'climat_scolaire': np.random.beta(3, 2, n_eleves) * 9 + 1,
            'soutien_scolaire': np.random.choice(['Oui', 'Non'], n_eleves, p=[0.3, 0.7]),
            
            # Activit√©s extrascolaires
            'sport': np.random.choice(['Oui', 'Non'], n_eleves, p=[0.6, 0.4]),
            'musique': np.random.choice(['Oui', 'Non'], n_eleves, p=[0.4, 0.6]),
            'lecture_loisir': np.random.gamma(1.5, 2, n_eleves).clip(0, 10)
        }
        
        # Cr√©er des corr√©lations r√©alistes
        df = pd.DataFrame(donnees_synth)
        
        # Ajuster les notes en fonction des facteurs influents
        for i in range(len(df)):
            bonus = 0
            
            # Impact du temps de devoirs
            if df.loc[i, 'heures_devoirs'] > 3:
                bonus += 1.5
            
            # Impact du sommeil
            if 7 <= df.loc[i, 'heures_sommeil'] <= 9:
                bonus += 1
            
            # Impact de la motivation
            bonus += (df.loc[i, 'motivation'] - 5) * 0.3
            
            # Impact du suivi parental
            if df.loc[i, 'suivi_parental'] == 'Fort':
                bonus += 1.2
            elif df.loc[i, 'suivi_parental'] == 'Faible':
                bonus -= 0.8
            
            # Impact du niveau d'√©tudes des parents
            if df.loc[i, 'niveau_etudes_parents'] == 'Sup√©rieur':
                bonus += 1
            elif df.loc[i, 'niveau_etudes_parents'] == 'Primaire':
                bonus -= 0.8
            
            # Impact n√©gatif du stress et du temps d'√©crans
            bonus -= (df.loc[i, 'stress'] - 5) * 0.2
            bonus -= max(0, df.loc[i, 'temps_ecrans'] - 4) * 0.15
            
            # Impact n√©gatif des absences
            bonus -= df.loc[i, 'absences'] * 0.05
            
            # Ajuster les notes
            df.loc[i, 'note_francais'] = np.clip(df.loc[i, 'note_francais'] + bonus, 0, 20)
            df.loc[i, 'note_maths'] = np.clip(df.loc[i, 'note_maths'] + bonus, 0, 20)
            df.loc[i, 'note_lecture'] = np.clip(df.loc[i, 'note_lecture'] + bonus, 0, 20)
        
        # Calculer la note moyenne
        df['note_moyenne'] = (df['note_francais'] + df['note_maths'] + df['note_lecture']) / 3
        
        # Cr√©er des variables composites
        df['score_assiduite'] = 10 - (df['absences'] * 0.15 + df['retards'] * 0.25)
        df['score_assiduite'] = df['score_assiduite'].clip(0, 10)
        
        df['equilibre_vie'] = df['heures_sommeil'] - df['temps_ecrans'] * 0.3
        df['equilibre_vie'] = df['equilibre_vie'].clip(0, 10)
        
        self.donnees = df
        print(f"‚úì Donn√©es synth√©tiques g√©n√©r√©es: {df.shape}")
        return df
    
    def exploration_donnees(self):
        """
        Effectue l'analyse exploratoire des donn√©es (EDA)
        """
        if self.donnees is None:
            print("‚úó Aucune donn√©e charg√©e")
            return
        
        print("="*60)
        print("EXPLORATION ET ANALYSE DES DONN√âES")
        print("="*60)
        
        # Informations g√©n√©rales
        print(f"\nüìä APER√áU G√âN√âRAL")
        print(f"   ‚Ä¢ Nombre d'√©l√®ves: {len(self.donnees)}")
        print(f"   ‚Ä¢ Nombre de variables: {len(self.donnees.columns)}")
        print(f"   ‚Ä¢ M√©moire utilis√©e: {self.donnees.memory_usage(deep=True).sum() / 1024:.1f} KB")
        
        # Valeurs manquantes
        print(f"\nüîç QUALIT√â DES DONN√âES")
        valeurs_manquantes = self.donnees.isnull().sum()
        if valeurs_manquantes.sum() > 0:
            print("   ‚Ä¢ Valeurs manquantes d√©tect√©es:")
            for col, count in valeurs_manquantes[valeurs_manquantes > 0].items():
                pct = (count / len(self.donnees)) * 100
                print(f"     - {col}: {count} ({pct:.1f}%)")
        else:
            print("   ‚Ä¢ ‚úì Aucune valeur manquante")
        
        # Statistiques descriptives
        print(f"\nüìà STATISTIQUES DESCRIPTIVES - PERFORMANCE")
        cols_notes = ['note_francais', 'note_maths', 'note_lecture', 'note_moyenne']
        stats_notes = self.donnees[cols_notes].describe()
        print(stats_notes.round(2))
        
        # D√©tection des valeurs aberrantes
        print(f"\n‚ö†Ô∏è  D√âTECTION D'ANOMALIES")
        for col in ['note_moyenne', 'absences', 'heures_devoirs']:
            if col in self.donnees.columns:
                Q1 = self.donnees[col].quantile(0.25)
                Q3 = self.donnees[col].quantile(0.75)
                IQR = Q3 - Q1
                outliers = len(self.donnees[(self.donnees[col] < Q1 - 1.5*IQR) | 
                                          (self.donnees[col] > Q3 + 1.5*IQR)])
                print(f"   ‚Ä¢ {col}: {outliers} valeurs aberrantes potentielles")
    
    def nettoyer_donnees(self):
        """
        Nettoie et pr√©pare les donn√©es pour la mod√©lisation
        """
        print(f"\nüßπ NETTOYAGE DES DONN√âES")
        
        df = self.donnees.copy()
        
        # Gestion des valeurs manquantes
        colonnes_numeriques = df.select_dtypes(include=[np.number]).columns
        colonnes_categorielles = df.select_dtypes(include=['object']).columns
        
        # Imputation num√©rique (m√©diane)
        for col in colonnes_numeriques:
            if df[col].isnull().sum() > 0:
                mediane = df[col].median()
                df[col].fillna(mediane, inplace=True)
                print(f"   ‚Ä¢ {col}: {df[col].isnull().sum()} valeurs imput√©es (m√©diane)")
        
        # Imputation cat√©gorielle (mode)
        for col in colonnes_categorielles:
            if df[col].isnull().sum() > 0:
                mode = df[col].mode()[0] if not df[col].mode().empty else 'Inconnu'
                df[col].fillna(mode, inplace=True)
                print(f"   ‚Ä¢ {col}: valeurs imput√©es (mode: {mode})")
        
        # Correction des types de donn√©es
        for col in df.columns:
            if 'age' in col.lower():
                df[col] = df[col].astype(int)
            elif any(word in col.lower() for word in ['note', 'score', 'heures']):
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        self.donnees_nettoyees = df
        print(f"   ‚úì Nettoyage termin√©")
        
        return df
    
    def visualiser_donnees(self):
        """
        Cr√©e des visualisations pour l'analyse exploratoire
        """
        if self.donnees_nettoyees is None:
            self.nettoyer_donnees()
        
        print(f"\nüìä G√âN√âRATION DES VISUALISATIONS")
        
        # Configuration
        fig = plt.figure(figsize=(20, 15))
        
        # 1. Distribution des notes
        plt.subplot(2, 3, 1)
        self.donnees_nettoyees['note_moyenne'].hist(bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('Distribution des Notes Moyennes', fontsize=14, fontweight='bold')
        plt.xlabel('Note Moyenne')
        plt.ylabel('Fr√©quence')
        plt.axvline(self.donnees_nettoyees['note_moyenne'].mean(), color='red', linestyle='--', 
                   label=f'Moyenne: {self.donnees_nettoyees["note_moyenne"].mean():.1f}')
        plt.legend()
        
        # 2. Relation temps devoirs vs notes
        plt.subplot(2, 3, 2)
        plt.scatter(self.donnees_nettoyees['heures_devoirs'], self.donnees_nettoyees['note_moyenne'], 
                   alpha=0.6, color='green')
        plt.title('Temps de Devoirs vs Performance', fontsize=14, fontweight='bold')
        plt.xlabel('Heures de Devoirs/jour')
        plt.ylabel('Note Moyenne')
        
        # Ligne de tendance
        z = np.polyfit(self.donnees_nettoyees['heures_devoirs'], self.donnees_nettoyees['note_moyenne'], 1)
        p = np.poly1d(z)
        plt.plot(self.donnees_nettoyees['heures_devoirs'], p(self.donnees_nettoyees['heures_devoirs']), 
                "r--", alpha=0.8)
        
        # 3. Impact du suivi parental
        plt.subplot(2, 3, 3)
        suivi_notes = self.donnees_nettoyees.groupby('suivi_parental')['note_moyenne'].mean()
        suivi_notes.plot(kind='bar', color=['lightcoral', 'gold', 'lightgreen'])
        plt.title('Impact du Suivi Parental', fontsize=14, fontweight='bold')
        plt.xlabel('Niveau de Suivi Parental')
        plt.ylabel('Note Moyenne')
        plt.xticks(rotation=45)
        
        # 4. Corr√©lations principales
        plt.subplot(2, 3, 4)
        colonnes_correlation = ['note_moyenne', 'heures_devoirs', 'heures_sommeil', 
                              'motivation', 'absences', 'stress']
        corr_matrix = self.donnees_nettoyees[colonnes_correlation].corr()
        sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, 
                   square=True, cbar_kws={'shrink': .8})
        plt.title('Matrice de Corr√©lation', fontsize=14, fontweight='bold')
        
        # 5. Facteurs de risque
        plt.subplot(2, 3, 5)
        eleves_difficulte = self.donnees_nettoyees[self.donnees_nettoyees['note_moyenne'] < 
                                                 self.donnees_nettoyees['note_moyenne'].quantile(0.25)]
        facteurs_risque = {
            'Absences √©lev√©es': len(eleves_difficulte[eleves_difficulte['absences'] > 15]),
            'Sommeil insuffisant': len(eleves_difficulte[eleves_difficulte['heures_sommeil'] < 7]),
            'Temps √©crans excessif': len(eleves_difficulte[eleves_difficulte['temps_ecrans'] > 6]),
            'Faible motivation': len(eleves_difficulte[eleves_difficulte['motivation'] < 5])
        }
        
        plt.bar(facteurs_risque.keys(), facteurs_risque.values(), color='orange', alpha=0.7)
        plt.title('Facteurs de Risque (25% √©l√®ves en difficult√©)', fontsize=14, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.ylabel('Nombre d\'√©l√®ves')
        
        # 6. Performance par type d'√©tablissement
        plt.subplot(2, 3, 6)
        perf_etablissement = self.donnees_nettoyees.groupby('type_etablissement')['note_moyenne'].mean()
        perf_etablissement.plot(kind='bar', color=['steelblue', 'darkorange'])
        plt.title('Performance par Type d\'√âtablissement', fontsize=14, fontweight='bold')
        plt.xlabel('Type d\'√âtablissement')
        plt.ylabel('Note Moyenne')
        plt.xticks(rotation=0)
        
        plt.tight_layout()
        plt.show()
        
        print("   ‚úì Visualisations g√©n√©r√©es")
    
    def preparer_modelisation(self):
        """
        Pr√©pare les donn√©es pour la mod√©lisation (variables X et y)
        """
        if self.donnees_nettoyees is None:
            self.nettoyer_donnees()
        
        print(f"\nüîß PR√âPARATION POUR LA MOD√âLISATION")
        
        # D√©finir les variables explicatives (X) et la cible (y)
        colonnes_exclues = ['note_francais', 'note_maths', 'note_lecture', 'note_moyenne']
        X = self.donnees_nettoyees.drop(columns=colonnes_exclues)
        y = self.donnees_nettoyees['note_moyenne']
        
        # Identifier les colonnes num√©riques et cat√©gorielles
        colonnes_numeriques = X.select_dtypes(include=[np.number]).columns.tolist()
        colonnes_categorielles = X.select_dtypes(include=['object']).columns.tolist()
        
        print(f"   ‚Ä¢ Variables num√©riques: {len(colonnes_numeriques)}")
        print(f"   ‚Ä¢ Variables cat√©gorielles: {len(colonnes_categorielles)}")
        
        # Cr√©er le preprocesseur
        preprocesseur = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), colonnes_numeriques),
                ('cat', OneHotEncoder(drop='first', sparse_output=False), colonnes_categorielles)
            ])
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=None
        )
        
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        self.preprocesseur = preprocesseur
        
        print(f"   ‚Ä¢ √âchantillon d'entra√Ænement: {len(X_train)} √©l√®ves")
        print(f"   ‚Ä¢ √âchantillon de test: {len(X_test)} √©l√®ves")
        print(f"   ‚úì Pr√©paration termin√©e")
        
        return X_train, X_test, y_train, y_test
    
    def entrainer_modeles(self):
        """
        Entra√Æne et compare diff√©rents mod√®les de machine learning
        """
        if self.X_train is None:
            self.preparer_modelisation()
        
        print(f"\nü§ñ ENTRA√éNEMENT DES MOD√àLES")
        print("="*50)
        
        # D√©finir les mod√®les √† tester
        modeles_config = {
            'R√©gression Lin√©aire': LinearRegression(),
            'For√™t Al√©atoire': RandomForestRegressor(n_estimators=100, random_state=42),
            'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0)
        }
        
        resultats = {}
        
        for nom, modele in modeles_config.items():
            print(f"\nüîÑ Entra√Ænement: {nom}")
            
            # Cr√©er un pipeline avec preprocessing
            pipeline = Pipeline([
                ('preprocesseur', self.preprocesseur),
                ('modele', modele)
            ])
            
            # Validation crois√©e
            scores_cv = cross_val_score(pipeline, self.X_train, self.y_train, 
                                      cv=5, scoring='neg_mean_squared_error')
            rmse_cv = np.sqrt(-scores_cv)
            
            # Entra√Ænement sur l'ensemble complet
            pipeline.fit(self.X_train, self.y_train)
            
            # Pr√©dictions sur le test
            y_pred = pipeline.predict(self.X_test)
            
            # M√©triques
            rmse = np.sqrt(mean_squared_error(self.y_test, y_pred))
            mae = mean_absolute_error(self.y_test, y_pred)
            r2 = r2_score(self.y_test, y_pred)
            
            resultats[nom] = {
                'pipeline': pipeline,
                'RMSE_CV': rmse_cv.mean(),
                'RMSE_Test': rmse,
                'MAE': mae,
                'R¬≤': r2,
                'y_pred': y_pred
            }
            
            print(f"   ‚Ä¢ RMSE (Validation Crois√©e): {rmse_cv.mean():.3f} (¬±{rmse_cv.std():.3f})")
            print(f"   ‚Ä¢ RMSE (Test): {rmse:.3f}")
            print(f"   ‚Ä¢ MAE: {mae:.3f}")
            print(f"   ‚Ä¢ R¬≤: {r2:.3f}")
        
        self.modeles = resultats
        
        # S√©lectionner le meilleur mod√®le
        meilleur_nom = min(resultats.keys(), key=lambda x: resultats[x]['RMSE_Test'])
        self.meilleur_modele = resultats[meilleur_nom]['pipeline']
        
        print(f"\nüèÜ MEILLEUR MOD√àLE: {meilleur_nom}")
        print(f"   ‚Ä¢ RMSE: {resultats[meilleur_nom]['RMSE_Test']:.3f}")
        print(f"   ‚Ä¢ R¬≤: {resultats[meilleur_nom]['R¬≤']:.3f}")
        
        return resultats
    
    def analyser_importance_variables(self):
        """
        Analyse l'importance des variables du meilleur mod√®le
        """
        if self.meilleur_modele is None:
            print("‚úó Aucun mod√®le entra√Æn√©")
            return
        
        print(f"\nüéØ ANALYSE DE L'IMPORTANCE DES VARIABLES")
        
        # R√©cup√©rer le mod√®le depuis le pipeline
        modele = self.meilleur_modele.named_steps['modele']
        preprocesseur = self.meilleur_modele.named_steps['preprocesseur']
        
        # Obtenir les noms des features apr√®s preprocessing
        feature_names = []
        
        # Features num√©riques
        num_features = preprocesseur.named_transformers_['num'].get_feature_names_out()
        feature_names.extend(num_features)
        
        # Features cat√©gorielles
        if 'cat' in preprocesseur.named_transformers_:
            cat_features = preprocesseur.named_transformers_['cat'].get_feature_names_out()
            feature_names.extend(cat_features)
        
        # Extraire l'importance
        if hasattr(modele, 'feature_importances_'):
            importances = modele.feature_importances_
        elif hasattr(modele, 'coef_'):
            importances = np.abs(modele.coef_)
        else:
            print("   ‚ö†Ô∏è Impossible d'extraire l'importance des variables")
            return
        
        # Cr√©er un DataFrame des importances
        importance_df = pd.DataFrame({
            'Variable': feature_names,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        
        # Afficher le top 15
        print(f"\nüìä TOP 15 DES VARIABLES LES PLUS IMPORTANTES:")
        print("-" * 60)
        for i, (_, row) in enumerate(importance_df.head(15).iterrows(), 1):
            print(f"{i:2d}. {row['Variable']:<30} {row['Importance']:.4f}")
        
        # Visualisation
        plt.figure(figsize=(12, 8))
        top_features = importance_df.head(15)
        
        bars = plt.barh(range(len(top_features)), top_features['Importance'], color='steelblue', alpha=0.8)
        plt.yticks(range(len(top_features)), top_features['Variable'])
        plt.xlabel('Importance')
        plt.title('Top 15 des Variables les Plus Importantes pour Pr√©dire la R√©ussite Scolaire', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.gca().invert_yaxis()
        
        # Ajouter les valeurs sur les barres
        for i, bar in enumerate(bars):
            width = bar.get_width()
            plt.text(width + max(top_features['Importance']) * 0.01, bar.get_y() + bar.get_height()/2,
                    f'{width:.3f}', ha='left', va='center', fontsize=9)
        
        plt.tight_layout()
        plt.show()
        
        return importance_df
    
    def generer_rapport(self):
        """
        G√©n√®re un rapport de synth√®se automatis√©
        """
        print(f"\nüìÑ G√âN√âRATION DU RAPPORT DE SYNTH√àSE")
        print("="*60)
        
        if self.donnees is None:
            print("‚úó Aucune donn√©e disponible")
            return
        
        rapport = []
        rapport.append("# RAPPORT D'ANALYSE - PERFORMANCES SCOLAIRES")
        rapport.append("=" * 60)
        rapport.append("")
        
        # Section 1: R√©sum√© ex√©cutif
        rapport.append("## 1. R√âSUM√â EX√âCUTIF")
        rapport.append("")
        rapport.append(f"Cette analyse porte sur un √©chantillon de {len(self.donnees)} √©l√®ves.")
        
        if self.donnees_nettoyees is not None:
            note_moyenne = self.donnees_nettoyees['note_moyenne'].mean()
            note_mediane = self.donnees_nettoyees['note_moyenne'].median()
            note_std = self.donnees_nettoyees['note_moyenne'].std()
            
            rapport.append(f"- Note moyenne g√©n√©rale: {note_moyenne:.2f}/20")
            rapport.append(f"- Note m√©diane: {note_mediane:.2f}/20") 
            rapport.append(f"- √âcart-type: {note_std:.2f}")
            
            # Identification des √©l√®ves en difficult√©
            eleves_difficulte = len(self.donnees_nettoyees[self.donnees_nettoyees['note_moyenne'] < 10])
            pct_difficulte = (eleves_difficulte / len(self.donnees_nettoyees)) * 100
            rapport.append(f"- √âl√®ves en difficult√© (<10/20): {eleves_difficulte} ({pct_difficulte:.1f}%)")
        
        rapport.append("")
        
        # Section 2: Performance du mod√®le
        if self.modeles:
            rapport.append("## 2. PERFORMANCE DU MOD√àLE PR√âDICTIF")
            rapport.append("")
            
            meilleur_nom = min(self.modeles.keys(), key=lambda x: self.modeles[x]['RMSE_Test'])
            meilleur_resultat = self.modeles[meilleur_nom]
            
            rapport.append(f"Le meilleur mod√®le identifi√© est: **{meilleur_nom}**")
            rapport.append("")
            rapport.append("### M√©triques de performance:")
            rapport.append(f"- RMSE: {meilleur_resultat['RMSE_Test']:.3f} points")
            rapport.append(f"- MAE: {meilleur_resultat['MAE']:.3f} points")
            rapport.append(f"- R¬≤: {meilleur_resultat['R¬≤']:.3f} ({meilleur_resultat['R¬≤']*100:.1f}% de variance expliqu√©e)")
            rapport.append("")
            rapport.append("### Interpr√©tation:")
            if meilleur_resultat['R¬≤'] > 0.7:
                rapport.append("‚úì Mod√®le tr√®s performant - pr√©dictions fiables")
            elif meilleur_resultat['R¬≤'] > 0.5:
                rapport.append("‚óã Mod√®le moyennement performant - pr√©dictions mod√©r√©ment fiables")
            else:
                rapport.append("‚ö† Mod√®le peu performant - pr√©dictions √† interpr√©ter avec prudence")
        
        rapport.append("")
        
        # Section 3: Facteurs cl√©s de r√©ussite
        rapport.append("## 3. FACTEURS CL√âS DE R√âUSSITE")
        rapport.append("")
        
        if self.donnees_nettoyees is not None:
            # Corr√©lations importantes
            colonnes_correlation = ['note_moyenne', 'heures_devoirs', 'heures_sommeil', 
                                  'motivation', 'absences', 'stress']
            corr_avec_notes = self.donnees_nettoyees[colonnes_correlation].corr()['note_moyenne'].abs()
            top_correlations = corr_avec_notes.drop('note_moyenne').sort_values(ascending=False).head(5)
            
            rapport.append("### Variables les plus corr√©l√©es √† la r√©ussite:")
            for var, corr in top_correlations.items():
                rapport.append(f"- {var}: {corr:.3f}")
            
            rapport.append("")
            
            # Analyse par groupe
            rapport.append("### Analyse comparative par groupes:")
            
            # Suivi parental
            if 'suivi_parental' in self.donnees_nettoyees.columns:
                suivi_stats = self.donnees_nettoyees.groupby('suivi_parental')['note_moyenne'].agg(['mean', 'count'])
                rapport.append("")
                rapport.append("**Impact du suivi parental:**")
                for niveau, stats in suivi_stats.iterrows():
                    rapport.append(f"- {niveau}: {stats['mean']:.2f}/20 (n={stats['count']})")
            
            # Type d'√©tablissement
            if 'type_etablissement' in self.donnees_nettoyees.columns:
                etab_stats = self.donnees_nettoyees.groupby('type_etablissement')['note_moyenne'].agg(['mean', 'count'])
                rapport.append("")
                rapport.append("**Performance par type d'√©tablissement:**")
                for type_etab, stats in etab_stats.iterrows():
                    rapport.append(f"- {type_etab}: {stats['mean']:.2f}/20 (n={stats['count']})")
        
        rapport.append("")
        
        # Section 4: Recommandations
        rapport.append("## 4. RECOMMANDATIONS P√âDAGOGIQUES")
        rapport.append("")
        
        recommendations = [
            "### Actions prioritaires:",
            "",
            "1. **Optimiser le temps de travail personnel**",
            "   - Accompagner les √©l√®ves dans l'organisation de leurs devoirs",
            "   - Promouvoir des m√©thodes de travail efficaces",
            "   - Sensibiliser √† l'importance d'un temps d'√©tude r√©gulier",
            "",
            "2. **Am√©liorer l'hygi√®ne de vie**",
            "   - Sensibiliser aux bienfaits d'un sommeil suffisant (7-9h)",
            "   - R√©guler l'usage des √©crans, particuli√®rement le soir",
            "   - Encourager un √©quilibre entre travail et loisirs",
            "",
            "3. **Renforcer l'engagement parental**",
            "   - Organiser des ateliers pour les parents sur l'accompagnement scolaire",
            "   - Faciliter la communication √©cole-famille",
            "   - Proposer des ressources aux familles moins impliqu√©es",
            "",
            "4. **D√©velopper la motivation et la confiance**",
            "   - Mettre en place un syst√®me de reconnaissance des progr√®s",
            "   - Proposer un accompagnement personnalis√© aux √©l√®ves en difficult√©",
            "   - Organiser des activit√©s valorisant les diff√©rents types de talents",
            "",
            "5. **Pr√©venir l'absent√©isme**",
            "   - Identifier pr√©cocement les √©l√®ves √† risque",
            "   - Mettre en place un suivi individualis√©",
            "   - D√©velopper des strat√©gies de rem√©diation rapide"
        ]
        
        rapport.extend(recommendations)
        rapport.append("")
        
        # Section 5: M√©thodologie
        rapport.append("## 5. M√âTHODOLOGIE")
        rapport.append("")
        rapport.append("### Donn√©es analys√©es:")
        if self.donnees is not None:
            rapport.append(f"- √âchantillon: {len(self.donnees)} √©l√®ves")
            rapport.append(f"- Variables: {len(self.donnees.columns)} indicateurs")
            rapport.append("- Cat√©gories: facteurs individuels, familiaux, scolaires et contextuels")
        
        rapport.append("")
        rapport.append("### Mod√®les test√©s:")
        if self.modeles:
            for nom_modele in self.modeles.keys():
                rmse = self.modeles[nom_modele]['RMSE_Test']
                r2 = self.modeles[nom_modele]['R¬≤']
                rapport.append(f"- {nom_modele}: RMSE={rmse:.3f}, R¬≤={r2:.3f}")
        
        rapport.append("")
        rapport.append("### Validation:")
        rapport.append("- Validation crois√©e 5-folds sur l'ensemble d'entra√Ænement")
        rapport.append("- Test final sur 20% des donn√©es (√©chantillon ind√©pendant)")
        rapport.append("- M√©triques: RMSE, MAE, R¬≤ pour √©valuer la pr√©cision")
        
        rapport.append("")
        rapport.append("---")
        rapport.append("*Rapport g√©n√©r√© automatiquement par le syst√®me d'analyse pr√©dictive*")
        
        # Enregistrer le rapport
        contenu_rapport = "\n".join(rapport)
        
        try:
            with open('rapport_analyse_scolaire.md', 'w', encoding='utf-8') as f:
                f.write(contenu_rapport)
            print("   ‚úì Rapport sauvegard√©: rapport_analyse_scolaire.md")
        except Exception as e:
            print(f"   ‚ö† Erreur lors de la sauvegarde: {e}")
        
        # Afficher un aper√ßu
        print(f"\nüìã APER√áU DU RAPPORT:")
        print("-" * 40)
        for ligne in rapport[:20]:  # Afficher les 20 premi√®res lignes
            print(ligne)
        print("...")
        print(f"[Rapport complet: {len(rapport)} lignes]")
        
        return contenu_rapport
    
    def exporter_donnees_test(self, nom_fichier='test_synthetique.xlsx'):
        """
        Exporte un √©chantillon de donn√©es synth√©tiques pour les tests
        
        Args:
            nom_fichier (str): Nom du fichier de sortie
        """
        print(f"\nüíæ EXPORT DES DONN√âES DE TEST")
        
        # G√©n√©rer un petit √©chantillon de 30 √©l√®ves
        donnees_test = self.generer_donnees_synthetiques(30)
        
        try:
            donnees_test.to_excel(nom_fichier, index=False)
            print(f"   ‚úì Fichier export√©: {nom_fichier}")
            print(f"   ‚Ä¢ {len(donnees_test)} √©l√®ves")
            print(f"   ‚Ä¢ {len(donnees_test.columns)} variables")
            
            # Aper√ßu des donn√©es
            print(f"\nüìä Aper√ßu des donn√©es export√©es:")
            print(donnees_test[['age', 'note_moyenne', 'heures_devoirs', 'motivation', 'suivi_parental']].head())
            
        except Exception as e:
            print(f"   ‚úó Erreur lors de l'export: {e}")
        
        return donnees_test
    
    def analyse_complete(self, generer_donnees=True):
        """
        Lance l'analyse compl√®te de bout en bout
        
        Args:
            generer_donnees (bool): Si True, g√©n√®re des donn√©es synth√©tiques
        """
        print("üéØ LANCEMENT DE L'ANALYSE COMPL√àTE")
        print("=" * 70)
        
        try:
            # 1. Donn√©es
            if generer_donnees:
                self.generer_donnees_synthetiques()
            
            # 2. Exploration
            self.exploration_donnees()
            
            # 3. Nettoyage et visualisation
            self.nettoyer_donnees()
            self.visualiser_donnees()
            
            # 4. Mod√©lisation
            self.preparer_modelisation()
            self.entrainer_modeles()
            
            # 5. Analyse des r√©sultats
            self.analyser_importance_variables()
            
            # 6. Rapport et export
            self.generer_rapport()
            self.exporter_donnees_test()
            
            print(f"\nüéâ ANALYSE TERMIN√âE AVEC SUCC√àS!")
            print("=" * 50)
            print("üìÅ Fichiers g√©n√©r√©s:")
            print("   ‚Ä¢ rapport_analyse_scolaire.md")
            print("   ‚Ä¢ test_synthetique.xlsx")
            print("   ‚Ä¢ Graphiques affich√©s")
            
        except Exception as e:
            print(f"\n‚ùå ERREUR LORS DE L'ANALYSE: {e}")
            import traceback
            traceback.print_exc()


def main():
    """
    Fonction principale pour ex√©cuter l'analyse
    """
    print("üè´ SYST√àME D'ANALYSE PR√âDICTIVE DES PERFORMANCES SCOLAIRES")
    print("=" * 70)
    print("Version 1.0 - Sp√©cialis√© pour l'√©ducation")
    print()
    
    # Cr√©er l'analyseur
    analyseur = AnalyseurPerformanceScolaire()
    
    # Option 1: Charger des donn√©es existantes
    # analyseur.charger_donnees('joins.xlsx')
    
    # Option 2: Utiliser des donn√©es synth√©tiques (recommand√© pour la d√©monstration)
    print("üîÑ D√©marrage de l'analyse avec des donn√©es synth√©tiques...")
    print()
    
    # Lancer l'analyse compl√®te
    analyseur.analyse_complete(generer_donnees=True)
    
    print()
    print("üìö GUIDE D'UTILISATION:")
    print("1. Remplacez les donn√©es synth√©tiques par vos vraies donn√©es")
    print("2. Adaptez les variables selon votre contexte")
    print("3. Ajustez les seuils dans les recommandations")
    print("4. Personnalisez les visualisations selon vos besoins")
    print()
    print("üí° Pour plus d'aide, consultez la documentation dans le README.md")


if __name__ == "__main__":
    main()